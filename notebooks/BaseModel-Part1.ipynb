{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SELECT \n",
      "        financialinstrumentid,\n",
      "        date,\n",
      "        open,\n",
      "        high,\n",
      "        low,\n",
      "        close,\n",
      "        lastprice,\n",
      "        previouscloseprice,\n",
      "        volume,\n",
      "        totaltradingvolume,\n",
      "        totaltradevalue,\n",
      "        totalnumberoftradesexecuted,\n",
      "        tickersymbol,\n",
      "        securityseries,\n",
      "        settlementprice,\n",
      "        financialinstrumentname\n",
      "    FROM stock_data.tickers\n",
      "    WHERE financialinstrumentid IN ('500002',) AND date BETWEEN '2017-01-01' AND '2025-12-31'\n",
      "    ORDER BY financialinstrumentid, date ASC\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "If you really know what your doing, you can silence this warning with the warning module\n",
      "or by setting POLARS_ALLOW_FORKING_THREAD=1.\n",
      "\n",
      "2025-02-28 01:47:19,889\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the utils directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'utils')))\n",
    "\n",
    "import pandas as pd\n",
    "import modin.pandas as mpd\n",
    "from utils import clickhouse_data\n",
    "import numpy as np\n",
    "import talib\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define parameters\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2025-12-31'\n",
    "\n",
    "# Load and preprocess data\n",
    "large_cap = clickhouse_data.clickhouse_largecap(start_date, end_date)\n",
    "# mid_cap = clickhouse_data.clickhouse_midcap(start_date, end_date)\n",
    "# small_cap = clickhouse_data.clickhouse_smallcap(start_date, end_date)\n",
    "\n",
    "# # Fill missing dates\n",
    "# large_cap = clickhouse_data.fill_missing_dates_modin_optimized(large_cap)\n",
    "# mid_cap = clickhouse_data.fill_missing_dates_modin_optimized(mid_cap)\n",
    "# small_cap = clickhouse_data.fill_missing_dates_modin_optimized(small_cap)\n",
    "\n",
    "# Stack dataframes\n",
    "all_cap = mpd.concat([large_cap])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering functions with validations and importance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: <function DataFrame.shift> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "Please refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\n",
      "UserWarning: __array_ufunc__ is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: <function DataFrame.shift> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: <function DataFrame.shift> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: <function DataFrame.shift> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: __array_ufunc__ is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: __array_ufunc__ is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: __array_ufunc__ is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: __array_ufunc__ is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: <function Series.tolist> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: <function Series.tolist> is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "01:47:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "01:47:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib\n",
    "from prophet import Prophet\n",
    "\n",
    "def extract_all_features(df):\n",
    "    \"\"\"\n",
    "    Master function that:\n",
    "    1. Retains raw OHLCV & additional trading data.\n",
    "    2. Computes trend-based, volatility, liquidity, and microstructure features.\n",
    "    3. Computes advanced technical indicators.\n",
    "    4. Extracts seasonal components using Prophet.\n",
    "    5. Ensures all feature columns are complete and normalized.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "\n",
    "    # === Retain Raw Data for Reference ===\n",
    "    raw_cols = [\n",
    "        'date', 'open', 'high', 'low', 'close', 'lastprice', 'previouscloseprice',\n",
    "        'volume', 'totaltradingvolume', 'totaltradevalue', 'totalnumberoftradesexecuted'\n",
    "    ]\n",
    "    df = df[raw_cols]  # Ensure we only work with the relevant columns\n",
    "\n",
    "    # Ensure proper datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    # === Compute Derived Features ===\n",
    "    \n",
    "    ## 🔹 Trend-Based Features\n",
    "    df = clickhouse_data.compute_trend_features(df)\n",
    "\n",
    "    ## 🔹 Volatility Features\n",
    "    df = clickhouse_data.compute_volatility_features(df)\n",
    "\n",
    "    ## 🔹 Liquidity Features (Includes Total Trading Volume & Trade Value)\n",
    "    df = clickhouse_data.compute_liquidity_features(df)\n",
    "\n",
    "    ## 🔹 Market Microstructure Features (VWAP, etc.)\n",
    "    df = clickhouse_data.compute_microstructure_features(df)\n",
    "\n",
    "    # === Derived Features from Additional Trading Data ===\n",
    "\n",
    "    # 🔹 Previous Close Return (Gap Indicator)\n",
    "    df['prev_close_return'] = np.log(df['close'] / df['previouscloseprice'])\n",
    "\n",
    "    # 🔹 Trading Intensity (Total Trades / Volume)\n",
    "    df['trading_intensity'] = df['totalnumberoftradesexecuted'] / df['totaltradingvolume']\n",
    "\n",
    "    # 🔹 Turnover Ratio (Liquidity Proxy)\n",
    "    df['turnover_ratio'] = df['totaltradevalue'] / df['totaltradingvolume']\n",
    "\n",
    "    # 🔹 VWAP Ratio (Price Positioning)\n",
    "    df['vwap_ratio'] = df['close'] / df['vwap']\n",
    "    \n",
    "    # 🔹 High-Low & Close-Open Ratios\n",
    "    df['high_low_ratio'] = df['high'] / df['low']\n",
    "    df['close_open_ratio'] = df['close'] / df['open']\n",
    "\n",
    "    # === Advanced Technical Indicators ===\n",
    "    df['cci_20'] = talib.CCI(df['high'].values, df['low'].values, df['close'].values, timeperiod=20)\n",
    "    df['williams_r'] = talib.WILLR(df['high'].values, df['low'].values, df['close'].values, timeperiod=14)\n",
    "    df['stoch_k'], df['stoch_d'] = talib.STOCH(\n",
    "        df['high'].values, df['low'].values, df['close'].values, \n",
    "        fastk_period=14, slowk_period=3, slowd_period=3\n",
    "    )\n",
    "    df['chande_momentum'] = talib.CMO(df['close'].values, timeperiod=14)\n",
    "    df['ulcer_index'] = np.sqrt((df['close'].rolling(14).max().values - df['close'].values) ** 2 / 14)\n",
    "    df['obv'] = talib.OBV(df['close'].astype(float).values, df['volume'].astype(float).values)\n",
    "    df['chaikin_money_flow'] = talib.ADOSC(\n",
    "        df['high'].astype(float).values, df['low'].astype(float).values, df['close'].astype(float).values, df['volume'].astype(float).values, \n",
    "        fastperiod=3, slowperiod=10\n",
    "    )\n",
    "    \n",
    "    # === Extract Seasonality Features Using Prophet ===\n",
    "    df_prophet = df[['close']].reset_index()\n",
    "    df_prophet.columns = ['ds', 'y']\n",
    "\n",
    "    prophet = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False)\n",
    "    prophet.fit(df_prophet)\n",
    "\n",
    "    future = prophet.make_future_dataframe(periods=0)\n",
    "    forecast = prophet.predict(future)\n",
    "\n",
    "    df['seasonal_weekly'] = forecast['weekly']\n",
    "    df['seasonal_yearly'] = forecast['yearly']\n",
    "    \n",
    "    # Fill missing values (if any)\n",
    "    df = df.ffill()\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "featured_df = extract_all_features(all_cap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 01:47:40.401679: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-02-28 01:47:40.401730: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-02-28 01:47:40.401757: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-02-28 01:47:40.401791: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-28 01:47:40.401820: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 01:47:42.132611: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-02-28 01:47:42.144407: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:966] PluggableGraphOptimizer failed: INVALID_ARGUMENT: Failed to deserialize the `graph_buf`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.4451 - val_loss: 0.9809\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.2385 - val_loss: 0.6727\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.1691 - val_loss: 0.5432\n",
      "Epoch 4/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.1509 - val_loss: 0.4608\n",
      "Epoch 5/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.1367 - val_loss: 0.4411\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - loss: 0.1282 - val_loss: 0.4563\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 0.1255 - val_loss: 0.4339\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.1177 - val_loss: 0.4600\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.1163 - val_loss: 0.4107\n",
      "Epoch 10/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.1104 - val_loss: 0.4352\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.1081 - val_loss: 0.4355\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 0.1036 - val_loss: 0.4156\n",
      "Epoch 13/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.1063 - val_loss: 0.3850\n",
      "Epoch 14/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.1022 - val_loss: 0.3733\n",
      "Epoch 15/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1055 - val_loss: 0.3879\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.1043 - val_loss: 0.3621\n",
      "Epoch 17/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1001 - val_loss: 0.3451\n",
      "Epoch 18/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0987 - val_loss: 0.3448\n",
      "Epoch 19/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0970 - val_loss: 0.3527\n",
      "Epoch 20/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0948 - val_loss: 0.3257\n",
      "Epoch 21/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0937 - val_loss: 0.3372\n",
      "Epoch 22/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.0934 - val_loss: 0.3137\n",
      "Epoch 23/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0922 - val_loss: 0.3236\n",
      "Epoch 24/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 0.0919 - val_loss: 0.3033\n",
      "Epoch 25/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0910 - val_loss: 0.3307\n",
      "Epoch 26/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0857 - val_loss: 0.3171\n",
      "Epoch 27/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0843 - val_loss: 0.3175\n",
      "Epoch 28/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.0887 - val_loss: 0.2984\n",
      "Epoch 29/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.0839 - val_loss: 0.3015\n",
      "Epoch 30/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0825 - val_loss: 0.2975\n",
      "Epoch 31/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.0866 - val_loss: 0.3056\n",
      "Epoch 32/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0821 - val_loss: 0.3019\n",
      "Epoch 33/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0811 - val_loss: 0.2983\n",
      "Epoch 34/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.0798 - val_loss: 0.3020\n",
      "Epoch 35/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0836 - val_loss: 0.2997\n",
      "Epoch 36/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0798 - val_loss: 0.3011\n",
      "Epoch 37/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.0751 - val_loss: 0.3268\n",
      "Epoch 38/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0870 - val_loss: 0.2873\n",
      "Epoch 39/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0772 - val_loss: 0.2809\n",
      "Epoch 40/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0762 - val_loss: 0.2847\n",
      "Epoch 41/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.0785 - val_loss: 0.3168\n",
      "Epoch 42/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0765 - val_loss: 0.3012\n",
      "Epoch 43/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0724 - val_loss: 0.3006\n",
      "Epoch 44/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.0779 - val_loss: 0.3066\n",
      "Epoch 45/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0777 - val_loss: 0.2872\n",
      "Epoch 46/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0734 - val_loss: 0.3366\n",
      "Epoch 47/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0734 - val_loss: 0.3149\n",
      "Epoch 48/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - loss: 0.0724 - val_loss: 0.2979\n",
      "Epoch 49/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 0.0705 - val_loss: 0.2819\n",
      "Epoch 50/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 0.0706 - val_loss: 0.2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 01:50:00.208450: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:966] PluggableGraphOptimizer failed: INVALID_ARGUMENT: Failed to deserialize the `graph_buf`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n",
      "✅ Simple Feature Extraction Complete!\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "0",
         "rawType": "float16",
         "type": "float"
        },
        {
         "name": "1",
         "rawType": "float16",
         "type": "float"
        },
        {
         "name": "2",
         "rawType": "float16",
         "type": "float"
        },
        {
         "name": "3",
         "rawType": "float16",
         "type": "float"
        },
        {
         "name": "4",
         "rawType": "float16",
         "type": "float"
        },
        {
         "name": "5",
         "rawType": "float16",
         "type": "float"
        },
        {
         "name": "6",
         "rawType": "float16",
         "type": "float"
        },
        {
         "name": "7",
         "rawType": "float16",
         "type": "float"
        },
        {
         "name": "8",
         "rawType": "float16",
         "type": "float"
        },
        {
         "name": "9",
         "rawType": "float16",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cbfd53b9-0343-4db6-aab4-0ab06c828a5d",
       "rows": [
        [
         "2017-06-23 00:00:00",
         "1.76",
         "0.8066",
         "0.2773",
         "0.0",
         "7.73",
         "0.756",
         "0.4707",
         "4.49",
         "0.0",
         "0.0"
        ],
        [
         "2017-06-27 00:00:00",
         "2.656",
         "0.354",
         "0.0",
         "0.0",
         "7.953",
         "0.3252",
         "0.309",
         "4.47",
         "0.0",
         "0.0"
        ],
        [
         "2017-06-28 00:00:00",
         "2.863",
         "0.329",
         "0.0",
         "0.0",
         "7.906",
         "0.378",
         "0.3665",
         "4.316",
         "0.0",
         "0.0"
        ],
        [
         "2017-06-29 00:00:00",
         "2.242",
         "0.51",
         "0.0",
         "0.0",
         "7.934",
         "0.532",
         "0.5693",
         "4.484",
         "0.0",
         "0.0"
        ],
        [
         "2017-06-30 00:00:00",
         "3.11",
         "0.294",
         "0.0",
         "0.0",
         "7.977",
         "0.4014",
         "0.4937",
         "4.2",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-23</th>\n",
       "      <td>1.759766</td>\n",
       "      <td>0.806641</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.730469</td>\n",
       "      <td>0.755859</td>\n",
       "      <td>0.470703</td>\n",
       "      <td>4.488281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-27</th>\n",
       "      <td>2.656250</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.953125</td>\n",
       "      <td>0.325195</td>\n",
       "      <td>0.309082</td>\n",
       "      <td>4.468750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-28</th>\n",
       "      <td>2.863281</td>\n",
       "      <td>0.329102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.906250</td>\n",
       "      <td>0.377930</td>\n",
       "      <td>0.366455</td>\n",
       "      <td>4.316406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-29</th>\n",
       "      <td>2.242188</td>\n",
       "      <td>0.509766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.933594</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>0.569336</td>\n",
       "      <td>4.484375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>3.109375</td>\n",
       "      <td>0.293945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.976562</td>\n",
       "      <td>0.401367</td>\n",
       "      <td>0.493652</td>\n",
       "      <td>4.199219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2    3         4         5         6  \\\n",
       "date                                                                          \n",
       "2017-06-23  1.759766  0.806641  0.277344  0.0  7.730469  0.755859  0.470703   \n",
       "2017-06-27  2.656250  0.354004  0.000000  0.0  7.953125  0.325195  0.309082   \n",
       "2017-06-28  2.863281  0.329102  0.000000  0.0  7.906250  0.377930  0.366455   \n",
       "2017-06-29  2.242188  0.509766  0.000000  0.0  7.933594  0.532227  0.569336   \n",
       "2017-06-30  3.109375  0.293945  0.000000  0.0  7.976562  0.401367  0.493652   \n",
       "\n",
       "                   7    8    9  \n",
       "date                            \n",
       "2017-06-23  4.488281  0.0  0.0  \n",
       "2017-06-27  4.468750  0.0  0.0  \n",
       "2017-06-28  4.316406  0.0  0.0  \n",
       "2017-06-29  4.484375  0.0  0.0  \n",
       "2017-06-30  4.199219  0.0  0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 🚀 Enable Mixed Precision for Faster Training on M2 GPU\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# 🚀 Input Data Validation: Ensure there are no NaNs\n",
    "if featured_df.isnull().values.any():\n",
    "    raise ValueError(\"🚨 Warning: Input Data Contains NaN Values! Please handle missing values.\")\n",
    "\n",
    "# 🚀 Load and scale the data\n",
    "X = featured_df.dropna().astype(np.float32)  # Ensure correct dtype\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "input_dim = X_scaled.shape[1]\n",
    "\n",
    "# ✅ Define a Simple Autoencoder Model\n",
    "encoding_dim = min(10, input_dim // 2)  # Default to 10 or half of input features, whichever is smaller\n",
    "\n",
    "# ✅ Encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "x = Dense(encoding_dim * 4, activation='relu', kernel_initializer='he_normal')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(encoding_dim * 2, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "encoded = Dense(encoding_dim, activation='relu', kernel_initializer='he_normal', name=\"bottleneck\")(x)  # Latent space\n",
    "\n",
    "# ✅ Decoder\n",
    "x = Dense(encoding_dim * 2, activation='relu', kernel_initializer='he_normal')(encoded)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(encoding_dim * 4, activation='relu', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "decoded = Dense(input_dim, activation='linear')(x)  # Reconstruct input\n",
    "\n",
    "# ✅ Build Model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=tf.keras.losses.Huber(delta=1.0))\n",
    "\n",
    "# ✅ Manually Split the Data\n",
    "split_ratio = 0.9\n",
    "split_index = int(X_scaled.shape[0] * split_ratio)\n",
    "X_train, X_val = X_scaled[:split_index], X_scaled[split_index:]\n",
    "\n",
    "# ✅ Train Autoencoder Using NumPy Arrays\n",
    "autoencoder.fit(X_train, X_train, \n",
    "                validation_data=(X_val, X_val),  # ✅ Explicitly define validation data\n",
    "                epochs=50, \n",
    "                batch_size=32)\n",
    "\n",
    "# ✅ Extract Latent Features (Encoder Model)\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(\"bottleneck\").output)\n",
    "X_encoded = encoder.predict(X_scaled)\n",
    "\n",
    "# ✅ Convert Encoded Features to DataFrame\n",
    "encoded_features_df = pd.DataFrame(X_encoded, index=featured_df.index)\n",
    "\n",
    "print(\"✅ Simple Feature Extraction Complete!\")\n",
    "encoded_features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>lastprice</th>\n",
       "      <th>previouscloseprice</th>\n",
       "      <th>volume</th>\n",
       "      <th>totaltradingvolume</th>\n",
       "      <th>totaltradevalue</th>\n",
       "      <th>totalnumberoftradesexecuted</th>\n",
       "      <th>...</th>\n",
       "      <th>cci_20</th>\n",
       "      <th>williams_r</th>\n",
       "      <th>stoch_k</th>\n",
       "      <th>stoch_d</th>\n",
       "      <th>chande_momentum</th>\n",
       "      <th>ulcer_index</th>\n",
       "      <th>obv</th>\n",
       "      <th>chaikin_money_flow</th>\n",
       "      <th>seasonal_weekly</th>\n",
       "      <th>seasonal_yearly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-23</th>\n",
       "      <td>1500.35</td>\n",
       "      <td>1503.00</td>\n",
       "      <td>1430.20</td>\n",
       "      <td>1440.55</td>\n",
       "      <td>1440.55</td>\n",
       "      <td>1486.30</td>\n",
       "      <td>10963</td>\n",
       "      <td>10963</td>\n",
       "      <td>15950701</td>\n",
       "      <td>1256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10963.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-27</th>\n",
       "      <td>1445.00</td>\n",
       "      <td>1457.00</td>\n",
       "      <td>1428.85</td>\n",
       "      <td>1442.95</td>\n",
       "      <td>1442.95</td>\n",
       "      <td>1440.55</td>\n",
       "      <td>9015</td>\n",
       "      <td>9015</td>\n",
       "      <td>13001118</td>\n",
       "      <td>1135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19978.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-28</th>\n",
       "      <td>1443.00</td>\n",
       "      <td>1458.00</td>\n",
       "      <td>1425.80</td>\n",
       "      <td>1452.40</td>\n",
       "      <td>1452.40</td>\n",
       "      <td>1442.95</td>\n",
       "      <td>5662</td>\n",
       "      <td>5662</td>\n",
       "      <td>8171340</td>\n",
       "      <td>892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25640.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-29</th>\n",
       "      <td>1458.00</td>\n",
       "      <td>1479.00</td>\n",
       "      <td>1435.00</td>\n",
       "      <td>1439.80</td>\n",
       "      <td>1439.80</td>\n",
       "      <td>1452.40</td>\n",
       "      <td>8416</td>\n",
       "      <td>8416</td>\n",
       "      <td>12287156</td>\n",
       "      <td>804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17224.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>1419.25</td>\n",
       "      <td>1460.00</td>\n",
       "      <td>1411.25</td>\n",
       "      <td>1451.10</td>\n",
       "      <td>1451.10</td>\n",
       "      <td>1439.80</td>\n",
       "      <td>4764</td>\n",
       "      <td>4764</td>\n",
       "      <td>6900488</td>\n",
       "      <td>529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21988.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-10</th>\n",
       "      <td>7585.00</td>\n",
       "      <td>7710.00</td>\n",
       "      <td>7572.25</td>\n",
       "      <td>7694.10</td>\n",
       "      <td>7684.50</td>\n",
       "      <td>7564.55</td>\n",
       "      <td>5208</td>\n",
       "      <td>5208</td>\n",
       "      <td>39940871</td>\n",
       "      <td>1771</td>\n",
       "      <td>...</td>\n",
       "      <td>129.803746</td>\n",
       "      <td>-2.316602</td>\n",
       "      <td>92.911017</td>\n",
       "      <td>92.425667</td>\n",
       "      <td>18.316990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9664466.0</td>\n",
       "      <td>6180.854158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-12</th>\n",
       "      <td>7799.95</td>\n",
       "      <td>7799.95</td>\n",
       "      <td>7635.05</td>\n",
       "      <td>7654.95</td>\n",
       "      <td>7660.15</td>\n",
       "      <td>7725.80</td>\n",
       "      <td>3840</td>\n",
       "      <td>3840</td>\n",
       "      <td>29509077</td>\n",
       "      <td>1195</td>\n",
       "      <td>...</td>\n",
       "      <td>126.512055</td>\n",
       "      <td>-12.146597</td>\n",
       "      <td>90.529267</td>\n",
       "      <td>91.351614</td>\n",
       "      <td>15.650372</td>\n",
       "      <td>10.463278</td>\n",
       "      <td>-9668306.0</td>\n",
       "      <td>4842.355629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-16</th>\n",
       "      <td>7726.30</td>\n",
       "      <td>7945.00</td>\n",
       "      <td>7709.00</td>\n",
       "      <td>7893.40</td>\n",
       "      <td>7888.00</td>\n",
       "      <td>7697.45</td>\n",
       "      <td>10909</td>\n",
       "      <td>10909</td>\n",
       "      <td>85970063</td>\n",
       "      <td>3429</td>\n",
       "      <td>...</td>\n",
       "      <td>136.401314</td>\n",
       "      <td>-3.854198</td>\n",
       "      <td>93.894201</td>\n",
       "      <td>92.444829</td>\n",
       "      <td>26.513863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9657397.0</td>\n",
       "      <td>5807.772359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>6932.70</td>\n",
       "      <td>6947.45</td>\n",
       "      <td>6845.10</td>\n",
       "      <td>6929.05</td>\n",
       "      <td>6924.95</td>\n",
       "      <td>6913.95</td>\n",
       "      <td>3430</td>\n",
       "      <td>3430</td>\n",
       "      <td>23701429</td>\n",
       "      <td>1022</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.894064</td>\n",
       "      <td>-75.885121</td>\n",
       "      <td>69.371361</td>\n",
       "      <td>84.598277</td>\n",
       "      <td>-18.949662</td>\n",
       "      <td>257.733379</td>\n",
       "      <td>-9660827.0</td>\n",
       "      <td>6373.699490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07</th>\n",
       "      <td>6618.25</td>\n",
       "      <td>6742.60</td>\n",
       "      <td>6618.25</td>\n",
       "      <td>6704.50</td>\n",
       "      <td>6680.00</td>\n",
       "      <td>6618.85</td>\n",
       "      <td>4261</td>\n",
       "      <td>4261</td>\n",
       "      <td>28522327</td>\n",
       "      <td>1437</td>\n",
       "      <td>...</td>\n",
       "      <td>-92.565440</td>\n",
       "      <td>-93.499152</td>\n",
       "      <td>42.253843</td>\n",
       "      <td>68.506469</td>\n",
       "      <td>-25.649608</td>\n",
       "      <td>317.746891</td>\n",
       "      <td>-9665088.0</td>\n",
       "      <td>6550.761425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1838 rows x 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close  lastprice  previouscloseprice  \\\n",
       "date                                                                            \n",
       "2017-06-23  1500.35  1503.00  1430.20  1440.55    1440.55             1486.30   \n",
       "2017-06-27  1445.00  1457.00  1428.85  1442.95    1442.95             1440.55   \n",
       "2017-06-28  1443.00  1458.00  1425.80  1452.40    1452.40             1442.95   \n",
       "2017-06-29  1458.00  1479.00  1435.00  1439.80    1439.80             1452.40   \n",
       "2017-06-30  1419.25  1460.00  1411.25  1451.10    1451.10             1439.80   \n",
       "...             ...      ...      ...      ...        ...                 ...   \n",
       "2024-12-10  7585.00  7710.00  7572.25  7694.10    7684.50             7564.55   \n",
       "2024-12-12  7799.95  7799.95  7635.05  7654.95    7660.15             7725.80   \n",
       "2024-12-16  7726.30  7945.00  7709.00  7893.40    7888.00             7697.45   \n",
       "2025-01-01  6932.70  6947.45  6845.10  6929.05    6924.95             6913.95   \n",
       "2025-01-07  6618.25  6742.60  6618.25  6704.50    6680.00             6618.85   \n",
       "\n",
       "            volume  totaltradingvolume  totaltradevalue  \\\n",
       "date                                                      \n",
       "2017-06-23   10963               10963         15950701   \n",
       "2017-06-27    9015                9015         13001118   \n",
       "2017-06-28    5662                5662          8171340   \n",
       "2017-06-29    8416                8416         12287156   \n",
       "2017-06-30    4764                4764          6900488   \n",
       "...            ...                 ...              ...   \n",
       "2024-12-10    5208                5208         39940871   \n",
       "2024-12-12    3840                3840         29509077   \n",
       "2024-12-16   10909               10909         85970063   \n",
       "2025-01-01    3430                3430         23701429   \n",
       "2025-01-07    4261                4261         28522327   \n",
       "\n",
       "            totalnumberoftradesexecuted  ...      cci_20  williams_r  \\\n",
       "date                                     ...                           \n",
       "2017-06-23                         1256  ...    0.000000    0.000000   \n",
       "2017-06-27                         1135  ...    0.000000    0.000000   \n",
       "2017-06-28                          892  ...    0.000000    0.000000   \n",
       "2017-06-29                          804  ...    0.000000    0.000000   \n",
       "2017-06-30                          529  ...    0.000000    0.000000   \n",
       "...                                 ...  ...         ...         ...   \n",
       "2024-12-10                         1771  ...  129.803746   -2.316602   \n",
       "2024-12-12                         1195  ...  126.512055  -12.146597   \n",
       "2024-12-16                         3429  ...  136.401314   -3.854198   \n",
       "2025-01-01                         1022  ...  -56.894064  -75.885121   \n",
       "2025-01-07                         1437  ...  -92.565440  -93.499152   \n",
       "\n",
       "              stoch_k    stoch_d  chande_momentum  ulcer_index        obv  \\\n",
       "date                                                                        \n",
       "2017-06-23   0.000000   0.000000         0.000000     0.000000    10963.0   \n",
       "2017-06-27   0.000000   0.000000         0.000000     0.000000    19978.0   \n",
       "2017-06-28   0.000000   0.000000         0.000000     0.000000    25640.0   \n",
       "2017-06-29   0.000000   0.000000         0.000000     0.000000    17224.0   \n",
       "2017-06-30   0.000000   0.000000         0.000000     0.000000    21988.0   \n",
       "...               ...        ...              ...          ...        ...   \n",
       "2024-12-10  92.911017  92.425667        18.316990     0.000000 -9664466.0   \n",
       "2024-12-12  90.529267  91.351614        15.650372    10.463278 -9668306.0   \n",
       "2024-12-16  93.894201  92.444829        26.513863     0.000000 -9657397.0   \n",
       "2025-01-01  69.371361  84.598277       -18.949662   257.733379 -9660827.0   \n",
       "2025-01-07  42.253843  68.506469       -25.649608   317.746891 -9665088.0   \n",
       "\n",
       "            chaikin_money_flow  seasonal_weekly  seasonal_yearly  \n",
       "date                                                              \n",
       "2017-06-23            0.000000              0.0              0.0  \n",
       "2017-06-27            0.000000              0.0              0.0  \n",
       "2017-06-28            0.000000              0.0              0.0  \n",
       "2017-06-29            0.000000              0.0              0.0  \n",
       "2017-06-30            0.000000              0.0              0.0  \n",
       "...                        ...              ...              ...  \n",
       "2024-12-10         6180.854158              0.0              0.0  \n",
       "2024-12-12         4842.355629              0.0              0.0  \n",
       "2024-12-16         5807.772359              0.0              0.0  \n",
       "2025-01-01         6373.699490              0.0              0.0  \n",
       "2025-01-07         6550.761425              0.0              0.0  \n",
       "\n",
       "[1838 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
